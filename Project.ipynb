{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d846a56",
   "metadata": {},
   "source": [
    "# First training with crop_part_1 (real) and 1m_face_00 (fake) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f2fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54357fb1",
   "metadata": {},
   "source": [
    "## Reading training data and assigning to np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53396a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing images in the folder and shuffling filenames in case they are ordered by age,characteristics, etc...\n",
    "real_faces_file_list = glob.glob(\"crop_part1/train_1/*\")\n",
    "random.shuffle(real_faces_file_list)\n",
    "# Calculatin length for training and validation sets\n",
    "train_real_faces_length = int((len(real_faces_file_list) * TRAIN_RATIO))\n",
    "validation_real_faces_length =  int((len(real_faces_file_list) * VALIDATION_RATIO))\n",
    "\n",
    "# Reading real faces images and converting them to np arrays\n",
    "\n",
    "# for fname in real_faces_file_list:\n",
    "#     image = cv2.imread(fname)\n",
    "#     train_real_faces.append(np.array(image))\n",
    "                                      \n",
    "                                      \n",
    "                                      \n",
    "train_real_faces = np.array([np.array(cv2.imread(fname)) for fname in real_faces_file_list[:train_real_faces_length]])\n",
    "validation_real_faces = np.array([np.array(cv2.imread(fname)) for fname in real_faces_file_list[train_real_faces_length:]])\n",
    "\n",
    "# Label for real faces (0) np array of zeroes\n",
    "train_real_labels = np.full(train_real_faces_length,0)\n",
    "validation_real_labels = np.full(validation_real_faces_length,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb354fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing images in the folder and shuffling filenames in case they are ordered by age,characteristics, etc...\n",
    "fake_faces_file_list = glob.glob(\"./1m_faces_00-200x200/train_1/*\")\n",
    "random.shuffle(fake_faces_file_list)\n",
    "\n",
    "# Calculatin length for training and validation sets\n",
    "train_fake_faces_length = int(((len(fake_faces_file_list)-(len(fake_faces_file_list)-1000)) * TRAIN_RATIO))\n",
    "validation_fake_faces_length = int(((len(fake_faces_file_list)-(len(fake_faces_file_list)-1000)) * VALIDATION_RATIO))\n",
    "# Reading real faces images and converting them to np arrays\n",
    "train_fake_faces = np.array([np.array(cv2.imread(fname)) for fname in fake_faces_file_list[:train_fake_faces_length]])\n",
    "validation_fake_faces = np.array([np.array(cv2.imread(fname)) for fname in fake_faces_file_list[train_fake_faces_length:train_fake_faces_length+validation_fake_faces_length]])\n",
    "\n",
    "train_fake_labels = np.full(train_fake_faces_length, 0)\n",
    "validation_fake_labels = np.full(validation_fake_faces_length,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c3de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62a6b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200, 200, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_real_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d02098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake_faces_file_list[0].split(\"\\\\\")[1]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fake_faces_file_list[0].split(\"\\\\\")[1]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f2188a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-6-4b07764c360d>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-4b07764c360d>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    \"\"\"\"\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#FUNCTION FOR SPLITTING THE IMAGES IN SETS OF 1000 images per folder \n",
    "\"\"\"\"import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "files_list = glob.glob(\"crop_part1/*\")\n",
    "random.shuffle(files_list)\n",
    "i = 0\n",
    "for fname in files_list:\n",
    "    if(i == 1000):\n",
    "        break\n",
    "    if(\"train_\" in fname):\n",
    "        print(\"train_ folder\")\n",
    "        continue\n",
    "  \n",
    "    im_temp = cv2.imread(fname)\n",
    "    cv2.imwrite(\"/home/mgaldi/CS486/crop_part1/train_6/\"+fname.split(\"/\")[1], im_temp)\n",
    "    os.remove(\"/home/mgaldi/CS486/crop_part1/\"+fname.split(\"/\")[1])\n",
    "    i = i+1\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f382f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"im_rgb = cv2.cvtColor(train_real_faces[0], cv2.COLOR_BGR2RGB)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60135da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_faces = train_real_faces / 255.0\n",
    "train_fake_faces = train_fake_faces / 255.0\n",
    "#train_ps_faces = train_ps_faces / 255.0\n",
    "validation_real_faces = validation_real_faces / 255.0\n",
    "validation_fake_faces = validation_fake_faces / 255.0\n",
    "#validation_ps_faces = validation_ps_faces / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ff8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.concatenate((train_real_faces, train_fake_faces))#,train_ps_faces\n",
    "validation_x = np.concatenate((validation_real_faces, validation_fake_faces))#,validation_ps_faces\n",
    "train_y = np.concatenate((train_real_labels,train_fake_labels))#,train_ps_labels\n",
    "validation_y = np.concatenate((validation_real_labels,validation_fake_labels))#,validation_ps_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbb8c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.arange(train_real_fake_ps_faces.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dbddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e143567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(200, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(400, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deeb5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(200, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "# model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(400, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc254f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 200)     5600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 400)       720400    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 400)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 400)       1440400   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 400)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 400)       1440400   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 400)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 400)         1440400   \n",
      "=================================================================\n",
      "Total params: 5,047,200\n",
      "Trainable params: 5,047,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5271e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(400, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75bd3919",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax_cross_entropy_with_logits_v2() missing 2 required positional arguments: 'labels' and 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-edd8e8681fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer='adam',\n\u001b[0;32m----> 2\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0;31m# tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax_cross_entropy_with_logits_v2() missing 2 required positional arguments: 'labels' and 'logits'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.nn.softmax_cross_entropy_with_logits(),\n",
    "             # tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=10, batch_size=50,\n",
    "                    validation_data=(validation_x, validation_y),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "validation_loss, validation_acc = model.evaluate(validation_x,  validation_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bbfebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/tmp/model_train_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf552bbe",
   "metadata": {},
   "source": [
    "# Training model with 9k more pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ad3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow as tf\n",
    "TRAIN_RATIO = 0.8\n",
    "VALIDATION_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6686d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_faces_file_list = glob.glob(\"real_and_fake_face/training_real-200x200/*\")\n",
    "random.shuffle(real_faces_file_list)\n",
    "# train_real_faces_length = int(((len(real_faces_file_list)-(len(real_faces_file_list)-1000)) * TRAIN_RATIO))\n",
    "# validation_real_faces_length =  int(((len(real_faces_file_list)-(len(real_faces_file_list)-1000)) * VALIDATION_RATIO))\n",
    "train_real_faces_length = int((len(real_faces_file_list) * TRAIN_RATIO))\n",
    "validation_real_faces_length = int((len(real_faces_file_list) * VALIDATION_RATIO))\n",
    "train_real_faces = np.array([np.array(cv2.imread(fname)) for fname in real_faces_file_list[:train_real_faces_length]])\n",
    "validation_real_faces = np.array([np.array(cv2.imread(fname)) for fname in real_faces_file_list[train_real_faces_length:]])\n",
    "\n",
    "train_real_labels = np.full(train_real_faces_length,0)\n",
    "validation_real_labels = np.full(validation_real_faces_length,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95490d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n",
      "216\n",
      "864\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "print(train_real_faces_length)\n",
    "print(validation_real_faces_length)\n",
    "print(len(train_real_faces))\n",
    "print(len(validation_real_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8470c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_faces_file_list = glob.glob(\"real_and_fake_face/training_fake-200x200/*\")\n",
    "random.shuffle(fake_faces_file_list)\n",
    "# train_fake_faces_length = int(((len(fake_faces_file_list)-(len(fake_faces_file_list)-1000)) * TRAIN_RATIO))\n",
    "# validation_fake_faces_length = int(((len(fake_faces_file_list)-(len(fake_faces_file_list)-1000)) * VALIDATION_RATIO))\n",
    "train_fake_faces_length = int((len(fake_faces_file_list) * TRAIN_RATIO))\n",
    "validation_fake_faces_length = int((len(fake_faces_file_list) * VALIDATION_RATIO))\n",
    "\n",
    "train_fake_faces = np.array([np.array(cv2.imread(fname)) for fname in fake_faces_file_list[:train_fake_faces_length]])\n",
    "validation_fake_faces = np.array([np.array(cv2.imread(fname)) for fname in fake_faces_file_list[train_fake_faces_length:]])\n",
    "\n",
    "train_fake_labels = np.full(train_fake_faces_length,1)\n",
    "validation_fake_labels = np.full(validation_fake_faces_length,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bec5431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "192\n",
      "768\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "print(train_fake_faces_length)\n",
    "print(validation_fake_faces_length)\n",
    "print(len(train_fake_faces))\n",
    "print(len(validation_fake_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2cc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_faces = train_real_faces / 255.0\n",
    "train_fake_faces = train_fake_faces / 255.0\n",
    "#train_ps_faces = train_ps_faces / 255.0\n",
    "validation_real_faces = validation_real_faces / 255.0\n",
    "validation_fake_faces = validation_fake_faces / 255.0\n",
    "#validation_ps_faces = validation_ps_faces / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840b2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_fake_ps_faces = np.concatenate((train_real_faces, train_fake_faces))#,train_ps_faces\n",
    "validation_real_fake_ps_faces = np.concatenate((validation_real_faces, validation_fake_faces))#,validation_ps_faces\n",
    "train_real_fake_ps_labels = np.concatenate((train_real_labels,train_fake_labels))#,train_ps_labels\n",
    "validation_real_fake_ps_labels = np.concatenate((validation_real_labels,validation_fake_labels))#,validation_ps_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb364e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbad886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/tmp/model_train_10_ps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb652b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.2456 - accuracy: 0.5319"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 409\n  y sizes: 408\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3d7181896216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(train_real_fake_ps_faces, train_real_fake_ps_labels, epochs=15, batch_size=50,\n\u001b[0;32m----> 6\u001b[0;31m                     validation_data=(validation_real_fake_ps_faces, validation_real_fake_ps_labels),shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                 steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1215\u001b[0m           val_logs = self.evaluate(\n\u001b[1;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1647\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1648\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 409\n  y sizes: 408\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_real_fake_ps_faces, train_real_fake_ps_labels, epochs=15, batch_size=50,\n",
    "                    validation_data=(validation_real_fake_ps_faces, validation_real_fake_ps_labels),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b099f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 1s - loss: 3.0954 - accuracy: 0.5688\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "validation_loss, validation_acc = model.evaluate(validation_real_fake_ps_faces,  validation_real_fake_ps_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6099347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/tmp/model_train_11_ps_kaggle.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c832cdf",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8f45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f607e3c6",
   "metadata": {},
   "source": [
    "# Training with PS images (classified as real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017eefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(test_fake_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272bcca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict(test_real_fake_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d947853",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(len(preds)):\n",
    "#     if(preds[i][0] > preds[i][1]):\n",
    "#         print(\"Real\")\n",
    "#     else:\n",
    "#         print(\"Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a598307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(preds, columns=['Real', 'Fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_temp = cv2.imread(\"./real_image.jpg\")\n",
    "# im_temp = cv2.resize(im_temp, (200, 200))\n",
    "# cv2.imwrite(\"/home/mgaldi/CS486/real_image-200x200.jpg\", im_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_temp = cv2.imread(\"./real_image-200x200.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.array([im_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c757471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = img/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede30e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
